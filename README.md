Question 1: Read sample-file.txt, clean the words by removing punctuation and short tokens, and print the top 10 most frequent words.
Question 2: Use the same text file to construct bigrams (pairs of consecutive words) and identify the 5 most frequent pairs.
Question 3: Detect "near-duplicate" lines in the text file that become identical once lowercase conversion, whitespace, and punctuation are removed.
Question 4: Load student.csv, filter for high-engagement students based on study time, internet access, and absences, then save the results to a new CSV.
Question 5: Categorize students into "Low," "Medium," or "High" grade bands and create a summary table of their absences and internet access.
Question 6: Use crime.csv to classify areas as "High-Crime" or "Low-Crime" and compare the average unemployment rates between these two groups.
Question 7: Use BeautifulSoup to extract the page title and the first substantial paragraph (at least 50 characters) from the Data Science Wikipedia page.
Question 8: Scrape section headings from the same Wikipedia page, filtering out specific sections like "References" and saving the list to a text file.
Question 9: Extract the first data table from the Machine Learning Wikipedia page and save its contents into a structured CSV file.
Question 10: Design a reusable function to search for a case-insensitive keyword within a file and return the matching line numbers and text.
